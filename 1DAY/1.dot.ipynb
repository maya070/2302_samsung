{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.)\n",
      "l을 w로 미분한 값은 18.0\n"
     ]
    }
   ],
   "source": [
    "a = w*3\n",
    "\n",
    "l = a**2\n",
    "\n",
    "l.backward()\n",
    "\n",
    "print(w.grad)\n",
    "print('l을 w로 미분한 값은 {}'.format(w.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0/3000 w:0.020 b:0.020 cost: 1.667\n",
      "Epoch   100/3000 w:0.782 b:0.509 cost: 0.283\n",
      "Epoch   200/3000 w:0.981 b:0.403 cost: 0.230\n",
      "Epoch   300/3000 w:1.114 b:0.301 cost: 0.202\n",
      "Epoch   400/3000 w:1.212 b:0.225 cost: 0.186\n",
      "Epoch   500/3000 w:1.285 b:0.168 cost: 0.178\n",
      "Epoch   600/3000 w:1.340 b:0.125 cost: 0.173\n",
      "Epoch   700/3000 w:1.380 b:0.093 cost: 0.170\n",
      "Epoch   800/3000 w:1.411 b:0.070 cost: 0.169\n",
      "Epoch   900/3000 w:1.433 b:0.052 cost: 0.168\n",
      "Epoch  1000/3000 w:1.450 b:0.039 cost: 0.167\n",
      "Epoch  1100/3000 w:1.463 b:0.029 cost: 0.167\n",
      "Epoch  1200/3000 w:1.472 b:0.022 cost: 0.167\n",
      "Epoch  1300/3000 w:1.479 b:0.016 cost: 0.167\n",
      "Epoch  1400/3000 w:1.485 b:0.012 cost: 0.167\n",
      "Epoch  1500/3000 w:1.488 b:0.009 cost: 0.167\n",
      "Epoch  1600/3000 w:1.491 b:0.007 cost: 0.167\n",
      "Epoch  1700/3000 w:1.494 b:0.005 cost: 0.167\n",
      "Epoch  1800/3000 w:1.495 b:0.004 cost: 0.167\n",
      "Epoch  1900/3000 w:1.496 b:0.003 cost: 0.167\n",
      "Epoch  2000/3000 w:1.497 b:0.002 cost: 0.167\n",
      "Epoch  2100/3000 w:1.498 b:0.002 cost: 0.167\n",
      "Epoch  2200/3000 w:1.499 b:0.001 cost: 0.167\n",
      "Epoch  2300/3000 w:1.499 b:0.001 cost: 0.167\n",
      "Epoch  2400/3000 w:1.499 b:0.001 cost: 0.167\n",
      "Epoch  2500/3000 w:1.499 b:0.000 cost: 0.167\n",
      "Epoch  2600/3000 w:1.500 b:0.000 cost: 0.167\n",
      "Epoch  2700/3000 w:1.500 b:0.000 cost: 0.167\n",
      "Epoch  2800/3000 w:1.500 b:0.000 cost: 0.167\n",
      "Epoch  2900/3000 w:1.500 b:0.000 cost: 0.167\n",
      "Epoch  3000/3000 w:1.500 b:0.000 cost: 0.167\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "\n",
    "x_train = torch.FloatTensor([[0], [1], [1]])\n",
    "y_train = torch.FloatTensor([[0], [1], [2]])\n",
    "\n",
    "w = torch.zeros(1, requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "optimizer = optim.SGD([w, b] , lr = 0.01)\n",
    "\n",
    "nb_epochs = 3000\n",
    "\n",
    "for epoch in range( nb_epochs + 1):\n",
    "    \n",
    "    hypothesis = x_train * w + b \n",
    "\n",
    "    cost = torch.mean( (hypothesis - y_train)**2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0 :\n",
    "        print( 'Epoch {:5d}/{} w:{:.3f} b:{:.3f} cost: {:.3f}' \n",
    "              .format(epoch, nb_epochs, w.item(), b.item(), cost.item() ))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0/1000 cost: 29661.801\n",
      "tensor([0.2940, 0.2936, 0.2974], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   100/1000 cost: 1.564\n",
      "tensor([0.6735, 0.6610, 0.6762], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   200/1000 cost: 1.498\n",
      "tensor([0.6789, 0.6550, 0.6768], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   300/1000 cost: 1.435\n",
      "tensor([0.6843, 0.6491, 0.6773], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   400/1000 cost: 1.376\n",
      "tensor([0.6894, 0.6434, 0.6778], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   500/1000 cost: 1.320\n",
      "tensor([0.6945, 0.6379, 0.6783], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   600/1000 cost: 1.266\n",
      "tensor([0.6994, 0.6326, 0.6787], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   700/1000 cost: 1.216\n",
      "tensor([0.7042, 0.6273, 0.6791], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   800/1000 cost: 1.168\n",
      "tensor([0.7089, 0.6223, 0.6795], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   900/1000 cost: 1.122\n",
      "tensor([0.7135, 0.6173, 0.6798], grad_fn=<SqueezeBackward0>)\n",
      "Epoch  1000/1000 cost: 1.079\n",
      "tensor([0.7179, 0.6125, 0.6801], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "\n",
    "x_train = torch.FloatTensor([[73,80,75], [93,88,93], [89, 91, 90],[96,98,100],[73,66,70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "w = torch.zeros((3, 1), requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "optimizer = optim.SGD([w, b] , lr = 1e-5)\n",
    "\n",
    "nb_epochs = 1000\n",
    "\n",
    "for epoch in range( nb_epochs + 1):\n",
    "    \n",
    "    #hypothesis = x_train * w + b \n",
    "    hypothesis = x_train.matmul(w) + b \n",
    "    \n",
    "    #cost = torch.mean( (hypothesis - y_train)**2)\n",
    "    cost = F.mse_loss(hypothesis, y_train)\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0 :\n",
    "        print( 'Epoch {:5d}/{} cost: {:.3f}' \n",
    "              .format(epoch, nb_epochs, cost.item() ))\n",
    "        print( w.squeeze() ) \n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0/1000 cost: 29661.801\n",
      "tensor([0.2940, 0.2936, 0.2974], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   100/1000 cost: 1.564\n",
      "tensor([0.6735, 0.6610, 0.6762], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   200/1000 cost: 1.498\n",
      "tensor([0.6789, 0.6550, 0.6768], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   300/1000 cost: 1.435\n",
      "tensor([0.6843, 0.6491, 0.6773], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   400/1000 cost: 1.376\n",
      "tensor([0.6894, 0.6434, 0.6778], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   500/1000 cost: 1.320\n",
      "tensor([0.6945, 0.6379, 0.6783], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   600/1000 cost: 1.266\n",
      "tensor([0.6994, 0.6326, 0.6787], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   700/1000 cost: 1.216\n",
      "tensor([0.7042, 0.6273, 0.6791], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   800/1000 cost: 1.168\n",
      "tensor([0.7089, 0.6223, 0.6795], grad_fn=<SqueezeBackward0>)\n",
      "Epoch   900/1000 cost: 1.122\n",
      "tensor([0.7135, 0.6173, 0.6798], grad_fn=<SqueezeBackward0>)\n",
      "Epoch  1000/1000 cost: 1.079\n",
      "tensor([0.7179, 0.6125, 0.6801], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "\n",
    "x_train = torch.FloatTensor([[73,80,75], [93,88,93], [89, 91, 90],[96,98,100],[73,66,70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "\n",
    "w = torch.zeros((3, 1), requires_grad = True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "optimizer = optim.SGD([w, b] , lr = 1e-5)\n",
    "loss = nn.MSELoss() \n",
    "\n",
    "nb_epochs = 1000\n",
    "\n",
    "for epoch in range( nb_epochs + 1):\n",
    "    \n",
    "    #hypothesis = x_train * w + b \n",
    "    hypothesis = x_train.matmul(w) + b \n",
    "    \n",
    "    #cost = torch.mean( (hypothesis - y_train)**2)\n",
    "    #cost = F.mse_loss(hypothesis, y_train)\n",
    "    cost = loss(hypothesis, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0 :\n",
    "        print( 'Epoch {:5d}/{} cost: {:.3f}' \n",
    "              .format(epoch, nb_epochs, cost.item() ))\n",
    "        print( w.squeeze() ) \n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> linear model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear( 3,1 )   #-> 맞는 숫자 채우기 \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/500 Cost: 29520.441406\n",
      "Epoch    1/500 Cost: 9253.506836\n",
      "Epoch    2/500 Cost: 2900.899902\n",
      "Epoch    3/500 Cost: 909.694336\n",
      "Epoch    4/500 Cost: 285.556671\n",
      "Epoch    5/500 Cost: 89.922714\n",
      "Epoch    6/500 Cost: 28.601517\n",
      "Epoch    7/500 Cost: 9.380602\n",
      "Epoch    8/500 Cost: 3.355625\n",
      "Epoch    9/500 Cost: 1.466967\n",
      "Epoch   10/500 Cost: 0.874789\n",
      "Epoch   11/500 Cost: 0.689042\n",
      "Epoch   12/500 Cost: 0.630646\n",
      "Epoch   13/500 Cost: 0.612179\n",
      "Epoch   14/500 Cost: 0.606222\n",
      "Epoch   15/500 Cost: 0.604193\n",
      "Epoch   16/500 Cost: 0.603396\n",
      "Epoch   17/500 Cost: 0.602983\n",
      "Epoch   18/500 Cost: 0.602692\n",
      "Epoch   19/500 Cost: 0.602438\n",
      "Epoch   20/500 Cost: 0.602197\n",
      "Epoch   21/500 Cost: 0.601959\n",
      "Epoch   22/500 Cost: 0.601721\n",
      "Epoch   23/500 Cost: 0.601482\n",
      "Epoch   24/500 Cost: 0.601244\n",
      "Epoch   25/500 Cost: 0.601013\n",
      "Epoch   26/500 Cost: 0.600768\n",
      "Epoch   27/500 Cost: 0.600531\n",
      "Epoch   28/500 Cost: 0.600295\n",
      "Epoch   29/500 Cost: 0.600061\n",
      "Epoch   30/500 Cost: 0.599825\n",
      "Epoch   31/500 Cost: 0.599597\n",
      "Epoch   32/500 Cost: 0.599345\n",
      "Epoch   33/500 Cost: 0.599116\n",
      "Epoch   34/500 Cost: 0.598879\n",
      "Epoch   35/500 Cost: 0.598651\n",
      "Epoch   36/500 Cost: 0.598411\n",
      "Epoch   37/500 Cost: 0.598186\n",
      "Epoch   38/500 Cost: 0.597942\n",
      "Epoch   39/500 Cost: 0.597714\n",
      "Epoch   40/500 Cost: 0.597476\n",
      "Epoch   41/500 Cost: 0.597242\n",
      "Epoch   42/500 Cost: 0.597002\n",
      "Epoch   43/500 Cost: 0.596768\n",
      "Epoch   44/500 Cost: 0.596540\n",
      "Epoch   45/500 Cost: 0.596301\n",
      "Epoch   46/500 Cost: 0.596064\n",
      "Epoch   47/500 Cost: 0.595840\n",
      "Epoch   48/500 Cost: 0.595610\n",
      "Epoch   49/500 Cost: 0.595367\n",
      "Epoch   50/500 Cost: 0.595134\n",
      "Epoch   51/500 Cost: 0.594899\n",
      "Epoch   52/500 Cost: 0.594671\n",
      "Epoch   53/500 Cost: 0.594437\n",
      "Epoch   54/500 Cost: 0.594205\n",
      "Epoch   55/500 Cost: 0.593967\n",
      "Epoch   56/500 Cost: 0.593741\n",
      "Epoch   57/500 Cost: 0.593506\n",
      "Epoch   58/500 Cost: 0.593270\n",
      "Epoch   59/500 Cost: 0.593037\n",
      "Epoch   60/500 Cost: 0.592803\n",
      "Epoch   61/500 Cost: 0.592575\n",
      "Epoch   62/500 Cost: 0.592350\n",
      "Epoch   63/500 Cost: 0.592108\n",
      "Epoch   64/500 Cost: 0.591880\n",
      "Epoch   65/500 Cost: 0.591650\n",
      "Epoch   66/500 Cost: 0.591420\n",
      "Epoch   67/500 Cost: 0.591186\n",
      "Epoch   68/500 Cost: 0.590960\n",
      "Epoch   69/500 Cost: 0.590725\n",
      "Epoch   70/500 Cost: 0.590493\n",
      "Epoch   71/500 Cost: 0.590269\n",
      "Epoch   72/500 Cost: 0.590031\n",
      "Epoch   73/500 Cost: 0.589806\n",
      "Epoch   74/500 Cost: 0.589568\n",
      "Epoch   75/500 Cost: 0.589338\n",
      "Epoch   76/500 Cost: 0.589106\n",
      "Epoch   77/500 Cost: 0.588882\n",
      "Epoch   78/500 Cost: 0.588649\n",
      "Epoch   79/500 Cost: 0.588417\n",
      "Epoch   80/500 Cost: 0.588188\n",
      "Epoch   81/500 Cost: 0.587964\n",
      "Epoch   82/500 Cost: 0.587735\n",
      "Epoch   83/500 Cost: 0.587510\n",
      "Epoch   84/500 Cost: 0.587273\n",
      "Epoch   85/500 Cost: 0.587044\n",
      "Epoch   86/500 Cost: 0.586817\n",
      "Epoch   87/500 Cost: 0.586584\n",
      "Epoch   88/500 Cost: 0.586366\n",
      "Epoch   89/500 Cost: 0.586125\n",
      "Epoch   90/500 Cost: 0.585902\n",
      "Epoch   91/500 Cost: 0.585668\n",
      "Epoch   92/500 Cost: 0.585444\n",
      "Epoch   93/500 Cost: 0.585217\n",
      "Epoch   94/500 Cost: 0.584996\n",
      "Epoch   95/500 Cost: 0.584765\n",
      "Epoch   96/500 Cost: 0.584532\n",
      "Epoch   97/500 Cost: 0.584307\n",
      "Epoch   98/500 Cost: 0.584079\n",
      "Epoch   99/500 Cost: 0.583859\n",
      "Epoch  100/500 Cost: 0.583616\n",
      "Epoch  101/500 Cost: 0.583398\n",
      "Epoch  102/500 Cost: 0.583171\n",
      "Epoch  103/500 Cost: 0.582943\n",
      "Epoch  104/500 Cost: 0.582720\n",
      "Epoch  105/500 Cost: 0.582490\n",
      "Epoch  106/500 Cost: 0.582267\n",
      "Epoch  107/500 Cost: 0.582035\n",
      "Epoch  108/500 Cost: 0.581812\n",
      "Epoch  109/500 Cost: 0.581589\n",
      "Epoch  110/500 Cost: 0.581363\n",
      "Epoch  111/500 Cost: 0.581138\n",
      "Epoch  112/500 Cost: 0.580907\n",
      "Epoch  113/500 Cost: 0.580682\n",
      "Epoch  114/500 Cost: 0.580450\n",
      "Epoch  115/500 Cost: 0.580231\n",
      "Epoch  116/500 Cost: 0.580009\n",
      "Epoch  117/500 Cost: 0.579774\n",
      "Epoch  118/500 Cost: 0.579555\n",
      "Epoch  119/500 Cost: 0.579327\n",
      "Epoch  120/500 Cost: 0.579104\n",
      "Epoch  121/500 Cost: 0.578887\n",
      "Epoch  122/500 Cost: 0.578660\n",
      "Epoch  123/500 Cost: 0.578438\n",
      "Epoch  124/500 Cost: 0.578208\n",
      "Epoch  125/500 Cost: 0.577987\n",
      "Epoch  126/500 Cost: 0.577757\n",
      "Epoch  127/500 Cost: 0.577538\n",
      "Epoch  128/500 Cost: 0.577309\n",
      "Epoch  129/500 Cost: 0.577093\n",
      "Epoch  130/500 Cost: 0.576872\n",
      "Epoch  131/500 Cost: 0.576648\n",
      "Epoch  132/500 Cost: 0.576426\n",
      "Epoch  133/500 Cost: 0.576195\n",
      "Epoch  134/500 Cost: 0.575975\n",
      "Epoch  135/500 Cost: 0.575753\n",
      "Epoch  136/500 Cost: 0.575531\n",
      "Epoch  137/500 Cost: 0.575309\n",
      "Epoch  138/500 Cost: 0.575088\n",
      "Epoch  139/500 Cost: 0.574864\n",
      "Epoch  140/500 Cost: 0.574642\n",
      "Epoch  141/500 Cost: 0.574422\n",
      "Epoch  142/500 Cost: 0.574192\n",
      "Epoch  143/500 Cost: 0.573968\n",
      "Epoch  144/500 Cost: 0.573748\n",
      "Epoch  145/500 Cost: 0.573524\n",
      "Epoch  146/500 Cost: 0.573310\n",
      "Epoch  147/500 Cost: 0.573084\n",
      "Epoch  148/500 Cost: 0.572868\n",
      "Epoch  149/500 Cost: 0.572640\n",
      "Epoch  150/500 Cost: 0.572419\n",
      "Epoch  151/500 Cost: 0.572209\n",
      "Epoch  152/500 Cost: 0.571982\n",
      "Epoch  153/500 Cost: 0.571755\n",
      "Epoch  154/500 Cost: 0.571541\n",
      "Epoch  155/500 Cost: 0.571309\n",
      "Epoch  156/500 Cost: 0.571099\n",
      "Epoch  157/500 Cost: 0.570876\n",
      "Epoch  158/500 Cost: 0.570656\n",
      "Epoch  159/500 Cost: 0.570440\n",
      "Epoch  160/500 Cost: 0.570215\n",
      "Epoch  161/500 Cost: 0.569995\n",
      "Epoch  162/500 Cost: 0.569772\n",
      "Epoch  163/500 Cost: 0.569560\n",
      "Epoch  164/500 Cost: 0.569331\n",
      "Epoch  165/500 Cost: 0.569116\n",
      "Epoch  166/500 Cost: 0.568902\n",
      "Epoch  167/500 Cost: 0.568687\n",
      "Epoch  168/500 Cost: 0.568458\n",
      "Epoch  169/500 Cost: 0.568236\n",
      "Epoch  170/500 Cost: 0.568022\n",
      "Epoch  171/500 Cost: 0.567808\n",
      "Epoch  172/500 Cost: 0.567591\n",
      "Epoch  173/500 Cost: 0.567372\n",
      "Epoch  174/500 Cost: 0.567153\n",
      "Epoch  175/500 Cost: 0.566931\n",
      "Epoch  176/500 Cost: 0.566707\n",
      "Epoch  177/500 Cost: 0.566491\n",
      "Epoch  178/500 Cost: 0.566276\n",
      "Epoch  179/500 Cost: 0.566057\n",
      "Epoch  180/500 Cost: 0.565838\n",
      "Epoch  181/500 Cost: 0.565619\n",
      "Epoch  182/500 Cost: 0.565407\n",
      "Epoch  183/500 Cost: 0.565186\n",
      "Epoch  184/500 Cost: 0.564967\n",
      "Epoch  185/500 Cost: 0.564753\n",
      "Epoch  186/500 Cost: 0.564545\n",
      "Epoch  187/500 Cost: 0.564328\n",
      "Epoch  188/500 Cost: 0.564105\n",
      "Epoch  189/500 Cost: 0.563894\n",
      "Epoch  190/500 Cost: 0.563676\n",
      "Epoch  191/500 Cost: 0.563456\n",
      "Epoch  192/500 Cost: 0.563244\n",
      "Epoch  193/500 Cost: 0.563026\n",
      "Epoch  194/500 Cost: 0.562807\n",
      "Epoch  195/500 Cost: 0.562594\n",
      "Epoch  196/500 Cost: 0.562376\n",
      "Epoch  197/500 Cost: 0.562165\n",
      "Epoch  198/500 Cost: 0.561947\n",
      "Epoch  199/500 Cost: 0.561728\n",
      "Epoch  200/500 Cost: 0.561514\n",
      "Epoch  201/500 Cost: 0.561306\n",
      "Epoch  202/500 Cost: 0.561080\n",
      "Epoch  203/500 Cost: 0.560871\n",
      "Epoch  204/500 Cost: 0.560656\n",
      "Epoch  205/500 Cost: 0.560449\n",
      "Epoch  206/500 Cost: 0.560228\n",
      "Epoch  207/500 Cost: 0.560016\n",
      "Epoch  208/500 Cost: 0.559800\n",
      "Epoch  209/500 Cost: 0.559587\n",
      "Epoch  210/500 Cost: 0.559371\n",
      "Epoch  211/500 Cost: 0.559161\n",
      "Epoch  212/500 Cost: 0.558944\n",
      "Epoch  213/500 Cost: 0.558724\n",
      "Epoch  214/500 Cost: 0.558521\n",
      "Epoch  215/500 Cost: 0.558302\n",
      "Epoch  216/500 Cost: 0.558088\n",
      "Epoch  217/500 Cost: 0.557868\n",
      "Epoch  218/500 Cost: 0.557667\n",
      "Epoch  219/500 Cost: 0.557453\n",
      "Epoch  220/500 Cost: 0.557236\n",
      "Epoch  221/500 Cost: 0.557030\n",
      "Epoch  222/500 Cost: 0.556810\n",
      "Epoch  223/500 Cost: 0.556602\n",
      "Epoch  224/500 Cost: 0.556392\n",
      "Epoch  225/500 Cost: 0.556173\n",
      "Epoch  226/500 Cost: 0.555957\n",
      "Epoch  227/500 Cost: 0.555753\n",
      "Epoch  228/500 Cost: 0.555546\n",
      "Epoch  229/500 Cost: 0.555330\n",
      "Epoch  230/500 Cost: 0.555111\n",
      "Epoch  231/500 Cost: 0.554907\n",
      "Epoch  232/500 Cost: 0.554692\n",
      "Epoch  233/500 Cost: 0.554482\n",
      "Epoch  234/500 Cost: 0.554272\n",
      "Epoch  235/500 Cost: 0.554057\n",
      "Epoch  236/500 Cost: 0.553845\n",
      "Epoch  237/500 Cost: 0.553632\n",
      "Epoch  238/500 Cost: 0.553423\n",
      "Epoch  239/500 Cost: 0.553208\n",
      "Epoch  240/500 Cost: 0.553005\n",
      "Epoch  241/500 Cost: 0.552796\n",
      "Epoch  242/500 Cost: 0.552587\n",
      "Epoch  243/500 Cost: 0.552369\n",
      "Epoch  244/500 Cost: 0.552169\n",
      "Epoch  245/500 Cost: 0.551952\n",
      "Epoch  246/500 Cost: 0.551741\n",
      "Epoch  247/500 Cost: 0.551528\n",
      "Epoch  248/500 Cost: 0.551325\n",
      "Epoch  249/500 Cost: 0.551115\n",
      "Epoch  250/500 Cost: 0.550911\n",
      "Epoch  251/500 Cost: 0.550689\n",
      "Epoch  252/500 Cost: 0.550491\n",
      "Epoch  253/500 Cost: 0.550276\n",
      "Epoch  254/500 Cost: 0.550067\n",
      "Epoch  255/500 Cost: 0.549864\n",
      "Epoch  256/500 Cost: 0.549654\n",
      "Epoch  257/500 Cost: 0.549442\n",
      "Epoch  258/500 Cost: 0.549236\n",
      "Epoch  259/500 Cost: 0.549026\n",
      "Epoch  260/500 Cost: 0.548819\n",
      "Epoch  261/500 Cost: 0.548603\n",
      "Epoch  262/500 Cost: 0.548407\n",
      "Epoch  263/500 Cost: 0.548196\n",
      "Epoch  264/500 Cost: 0.547988\n",
      "Epoch  265/500 Cost: 0.547775\n",
      "Epoch  266/500 Cost: 0.547566\n",
      "Epoch  267/500 Cost: 0.547367\n",
      "Epoch  268/500 Cost: 0.547149\n",
      "Epoch  269/500 Cost: 0.546948\n",
      "Epoch  270/500 Cost: 0.546737\n",
      "Epoch  271/500 Cost: 0.546534\n",
      "Epoch  272/500 Cost: 0.546320\n",
      "Epoch  273/500 Cost: 0.546113\n",
      "Epoch  274/500 Cost: 0.545913\n",
      "Epoch  275/500 Cost: 0.545707\n",
      "Epoch  276/500 Cost: 0.545499\n",
      "Epoch  277/500 Cost: 0.545297\n",
      "Epoch  278/500 Cost: 0.545087\n",
      "Epoch  279/500 Cost: 0.544878\n",
      "Epoch  280/500 Cost: 0.544677\n",
      "Epoch  281/500 Cost: 0.544462\n",
      "Epoch  282/500 Cost: 0.544264\n",
      "Epoch  283/500 Cost: 0.544058\n",
      "Epoch  284/500 Cost: 0.543850\n",
      "Epoch  285/500 Cost: 0.543651\n",
      "Epoch  286/500 Cost: 0.543436\n",
      "Epoch  287/500 Cost: 0.543233\n",
      "Epoch  288/500 Cost: 0.543027\n",
      "Epoch  289/500 Cost: 0.542819\n",
      "Epoch  290/500 Cost: 0.542621\n",
      "Epoch  291/500 Cost: 0.542415\n",
      "Epoch  292/500 Cost: 0.542216\n",
      "Epoch  293/500 Cost: 0.542002\n",
      "Epoch  294/500 Cost: 0.541802\n",
      "Epoch  295/500 Cost: 0.541597\n",
      "Epoch  296/500 Cost: 0.541391\n",
      "Epoch  297/500 Cost: 0.541189\n",
      "Epoch  298/500 Cost: 0.540985\n",
      "Epoch  299/500 Cost: 0.540779\n",
      "Epoch  300/500 Cost: 0.540576\n",
      "Epoch  301/500 Cost: 0.540374\n",
      "Epoch  302/500 Cost: 0.540162\n",
      "Epoch  303/500 Cost: 0.539963\n",
      "Epoch  304/500 Cost: 0.539756\n",
      "Epoch  305/500 Cost: 0.539560\n",
      "Epoch  306/500 Cost: 0.539354\n",
      "Epoch  307/500 Cost: 0.539147\n",
      "Epoch  308/500 Cost: 0.538949\n",
      "Epoch  309/500 Cost: 0.538744\n",
      "Epoch  310/500 Cost: 0.538550\n",
      "Epoch  311/500 Cost: 0.538336\n",
      "Epoch  312/500 Cost: 0.538134\n",
      "Epoch  313/500 Cost: 0.537930\n",
      "Epoch  314/500 Cost: 0.537731\n",
      "Epoch  315/500 Cost: 0.537533\n",
      "Epoch  316/500 Cost: 0.537330\n",
      "Epoch  317/500 Cost: 0.537125\n",
      "Epoch  318/500 Cost: 0.536918\n",
      "Epoch  319/500 Cost: 0.536722\n",
      "Epoch  320/500 Cost: 0.536517\n",
      "Epoch  321/500 Cost: 0.536311\n",
      "Epoch  322/500 Cost: 0.536117\n",
      "Epoch  323/500 Cost: 0.535918\n",
      "Epoch  324/500 Cost: 0.535711\n",
      "Epoch  325/500 Cost: 0.535512\n",
      "Epoch  326/500 Cost: 0.535312\n",
      "Epoch  327/500 Cost: 0.535109\n",
      "Epoch  328/500 Cost: 0.534909\n",
      "Epoch  329/500 Cost: 0.534713\n",
      "Epoch  330/500 Cost: 0.534508\n",
      "Epoch  331/500 Cost: 0.534307\n",
      "Epoch  332/500 Cost: 0.534115\n",
      "Epoch  333/500 Cost: 0.533906\n",
      "Epoch  334/500 Cost: 0.533715\n",
      "Epoch  335/500 Cost: 0.533503\n",
      "Epoch  336/500 Cost: 0.533313\n",
      "Epoch  337/500 Cost: 0.533110\n",
      "Epoch  338/500 Cost: 0.532907\n",
      "Epoch  339/500 Cost: 0.532700\n",
      "Epoch  340/500 Cost: 0.532506\n",
      "Epoch  341/500 Cost: 0.532307\n",
      "Epoch  342/500 Cost: 0.532114\n",
      "Epoch  343/500 Cost: 0.531913\n",
      "Epoch  344/500 Cost: 0.531711\n",
      "Epoch  345/500 Cost: 0.531512\n",
      "Epoch  346/500 Cost: 0.531314\n",
      "Epoch  347/500 Cost: 0.531115\n",
      "Epoch  348/500 Cost: 0.530912\n",
      "Epoch  349/500 Cost: 0.530715\n",
      "Epoch  350/500 Cost: 0.530522\n",
      "Epoch  351/500 Cost: 0.530316\n",
      "Epoch  352/500 Cost: 0.530121\n",
      "Epoch  353/500 Cost: 0.529931\n",
      "Epoch  354/500 Cost: 0.529725\n",
      "Epoch  355/500 Cost: 0.529530\n",
      "Epoch  356/500 Cost: 0.529333\n",
      "Epoch  357/500 Cost: 0.529129\n",
      "Epoch  358/500 Cost: 0.528940\n",
      "Epoch  359/500 Cost: 0.528738\n",
      "Epoch  360/500 Cost: 0.528541\n",
      "Epoch  361/500 Cost: 0.528344\n",
      "Epoch  362/500 Cost: 0.528143\n",
      "Epoch  363/500 Cost: 0.527948\n",
      "Epoch  364/500 Cost: 0.527752\n",
      "Epoch  365/500 Cost: 0.527560\n",
      "Epoch  366/500 Cost: 0.527360\n",
      "Epoch  367/500 Cost: 0.527167\n",
      "Epoch  368/500 Cost: 0.526964\n",
      "Epoch  369/500 Cost: 0.526770\n",
      "Epoch  370/500 Cost: 0.526574\n",
      "Epoch  371/500 Cost: 0.526381\n",
      "Epoch  372/500 Cost: 0.526184\n",
      "Epoch  373/500 Cost: 0.525982\n",
      "Epoch  374/500 Cost: 0.525788\n",
      "Epoch  375/500 Cost: 0.525601\n",
      "Epoch  376/500 Cost: 0.525398\n",
      "Epoch  377/500 Cost: 0.525199\n",
      "Epoch  378/500 Cost: 0.525007\n",
      "Epoch  379/500 Cost: 0.524812\n",
      "Epoch  380/500 Cost: 0.524617\n",
      "Epoch  381/500 Cost: 0.524427\n",
      "Epoch  382/500 Cost: 0.524229\n",
      "Epoch  383/500 Cost: 0.524035\n",
      "Epoch  384/500 Cost: 0.523834\n",
      "Epoch  385/500 Cost: 0.523639\n",
      "Epoch  386/500 Cost: 0.523446\n",
      "Epoch  387/500 Cost: 0.523254\n",
      "Epoch  388/500 Cost: 0.523049\n",
      "Epoch  389/500 Cost: 0.522867\n",
      "Epoch  390/500 Cost: 0.522667\n",
      "Epoch  391/500 Cost: 0.522478\n",
      "Epoch  392/500 Cost: 0.522279\n",
      "Epoch  393/500 Cost: 0.522085\n",
      "Epoch  394/500 Cost: 0.521891\n",
      "Epoch  395/500 Cost: 0.521698\n",
      "Epoch  396/500 Cost: 0.521507\n",
      "Epoch  397/500 Cost: 0.521312\n",
      "Epoch  398/500 Cost: 0.521125\n",
      "Epoch  399/500 Cost: 0.520932\n",
      "Epoch  400/500 Cost: 0.520739\n",
      "Epoch  401/500 Cost: 0.520538\n",
      "Epoch  402/500 Cost: 0.520350\n",
      "Epoch  403/500 Cost: 0.520155\n",
      "Epoch  404/500 Cost: 0.519965\n",
      "Epoch  405/500 Cost: 0.519778\n",
      "Epoch  406/500 Cost: 0.519577\n",
      "Epoch  407/500 Cost: 0.519384\n",
      "Epoch  408/500 Cost: 0.519190\n",
      "Epoch  409/500 Cost: 0.519002\n",
      "Epoch  410/500 Cost: 0.518812\n",
      "Epoch  411/500 Cost: 0.518617\n",
      "Epoch  412/500 Cost: 0.518423\n",
      "Epoch  413/500 Cost: 0.518232\n",
      "Epoch  414/500 Cost: 0.518045\n",
      "Epoch  415/500 Cost: 0.517846\n",
      "Epoch  416/500 Cost: 0.517662\n",
      "Epoch  417/500 Cost: 0.517469\n",
      "Epoch  418/500 Cost: 0.517274\n",
      "Epoch  419/500 Cost: 0.517093\n",
      "Epoch  420/500 Cost: 0.516889\n",
      "Epoch  421/500 Cost: 0.516705\n",
      "Epoch  422/500 Cost: 0.516513\n",
      "Epoch  423/500 Cost: 0.516325\n",
      "Epoch  424/500 Cost: 0.516123\n",
      "Epoch  425/500 Cost: 0.515938\n",
      "Epoch  426/500 Cost: 0.515750\n",
      "Epoch  427/500 Cost: 0.515557\n",
      "Epoch  428/500 Cost: 0.515372\n",
      "Epoch  429/500 Cost: 0.515182\n",
      "Epoch  430/500 Cost: 0.514988\n",
      "Epoch  431/500 Cost: 0.514795\n",
      "Epoch  432/500 Cost: 0.514608\n",
      "Epoch  433/500 Cost: 0.514417\n",
      "Epoch  434/500 Cost: 0.514231\n",
      "Epoch  435/500 Cost: 0.514041\n",
      "Epoch  436/500 Cost: 0.513849\n",
      "Epoch  437/500 Cost: 0.513665\n",
      "Epoch  438/500 Cost: 0.513468\n",
      "Epoch  439/500 Cost: 0.513281\n",
      "Epoch  440/500 Cost: 0.513089\n",
      "Epoch  441/500 Cost: 0.512905\n",
      "Epoch  442/500 Cost: 0.512714\n",
      "Epoch  443/500 Cost: 0.512531\n",
      "Epoch  444/500 Cost: 0.512337\n",
      "Epoch  445/500 Cost: 0.512153\n",
      "Epoch  446/500 Cost: 0.511961\n",
      "Epoch  447/500 Cost: 0.511772\n",
      "Epoch  448/500 Cost: 0.511586\n",
      "Epoch  449/500 Cost: 0.511400\n",
      "Epoch  450/500 Cost: 0.511214\n",
      "Epoch  451/500 Cost: 0.511020\n",
      "Epoch  452/500 Cost: 0.510838\n",
      "Epoch  453/500 Cost: 0.510646\n",
      "Epoch  454/500 Cost: 0.510456\n",
      "Epoch  455/500 Cost: 0.510272\n",
      "Epoch  456/500 Cost: 0.510087\n",
      "Epoch  457/500 Cost: 0.509893\n",
      "Epoch  458/500 Cost: 0.509711\n",
      "Epoch  459/500 Cost: 0.509521\n",
      "Epoch  460/500 Cost: 0.509344\n",
      "Epoch  461/500 Cost: 0.509145\n",
      "Epoch  462/500 Cost: 0.508957\n",
      "Epoch  463/500 Cost: 0.508770\n",
      "Epoch  464/500 Cost: 0.508588\n",
      "Epoch  465/500 Cost: 0.508405\n",
      "Epoch  466/500 Cost: 0.508216\n",
      "Epoch  467/500 Cost: 0.508029\n",
      "Epoch  468/500 Cost: 0.507846\n",
      "Epoch  469/500 Cost: 0.507658\n",
      "Epoch  470/500 Cost: 0.507473\n",
      "Epoch  471/500 Cost: 0.507292\n",
      "Epoch  472/500 Cost: 0.507100\n",
      "Epoch  473/500 Cost: 0.506911\n",
      "Epoch  474/500 Cost: 0.506729\n",
      "Epoch  475/500 Cost: 0.506545\n",
      "Epoch  476/500 Cost: 0.506355\n",
      "Epoch  477/500 Cost: 0.506178\n",
      "Epoch  478/500 Cost: 0.505980\n",
      "Epoch  479/500 Cost: 0.505801\n",
      "Epoch  480/500 Cost: 0.505610\n",
      "Epoch  481/500 Cost: 0.505429\n",
      "Epoch  482/500 Cost: 0.505250\n",
      "Epoch  483/500 Cost: 0.505063\n",
      "Epoch  484/500 Cost: 0.504879\n",
      "Epoch  485/500 Cost: 0.504698\n",
      "Epoch  486/500 Cost: 0.504515\n",
      "Epoch  487/500 Cost: 0.504326\n",
      "Epoch  488/500 Cost: 0.504144\n",
      "Epoch  489/500 Cost: 0.503962\n",
      "Epoch  490/500 Cost: 0.503769\n",
      "Epoch  491/500 Cost: 0.503591\n",
      "Epoch  492/500 Cost: 0.503405\n",
      "Epoch  493/500 Cost: 0.503221\n",
      "Epoch  494/500 Cost: 0.503042\n",
      "Epoch  495/500 Cost: 0.502860\n",
      "Epoch  496/500 Cost: 0.502671\n",
      "Epoch  497/500 Cost: 0.502489\n",
      "Epoch  498/500 Cost: 0.502307\n",
      "Epoch  499/500 Cost: 0.502118\n",
      "Epoch  500/500 Cost: 0.501943\n"
     ]
    }
   ],
   "source": [
    "model = MRModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 500\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    # cost 계산\n",
    "    \n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 20번마다 로그 출력    \n",
    "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, cost.item()\n",
    "    ))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
