{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0VDw5asHQkFv"
   },
   "source": [
    "# < VGG >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, utils\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Set GPU Envrionment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Set Hyper-parameters\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training\n",
    "EPOCHS     = 10\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# For Optimizer\n",
    "LR         = 0.005\n",
    "WD         = 0.005\n",
    "MOMENTUM   = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Prepare the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - DataLoader for Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_CIFAR10 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        root      = './dataset/CIFAR10', \n",
    "        train     = True,\n",
    "        download  = True,\n",
    "        transform = transform_CIFAR10),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory = True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        root      = './dataset/CIFAR10', \n",
    "        train     = False,\n",
    "        download  = True,\n",
    "        transform = transform_CIFAR10),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pin_memory = True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnW5nKAk4y-U"
   },
   "source": [
    "# **The VGG network structure**\n",
    "\n",
    "\n",
    "*   The input of VGG is set to an RGB image of 224x244 size. The average RGB value is calculated for all images on the training set image, and then the image is input as an input to the VGG convolution network. A 3x3 or 1x1 filter is used, and the convolution step is fixed. . There are 3 VGG fully connected layers, which can vary from VGG11 to VGG19 according to the total number of convolutional layers + fully connected layers. The minimum VGG11 has 8 convolutional layers and 3 fully connected layers. The maximum VGG19 has 16 convolutional layers. +3 fully connected layers. In addition, the VGG network is not followed by a pooling layer behind each convolutional layer, or a total of 5 pooling layers distributed under different convolutional layers. The following figure is VGG Structure diagram:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Fv1fzAo3TEf"
   },
   "source": [
    "![vgg.png](https://raw.githubusercontent.com/blurred-machine/Data-Science/master/Deep%20Learning%20SOTA/img/vgg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O906a0gy5_kL"
   },
   "source": [
    "**VGG Network Configuration**\n",
    "\n",
    "Table 1 shows all network configurations. These networks follow the same design principles, but differ in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTw4kB1j6EgD"
   },
   "source": [
    "![vggpaper](https://raw.githubusercontent.com/blurred-machine/Data-Science/master/Deep%20Learning%20SOTA/img/netconvgg.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Make the Model (VGG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html\n",
    "\n",
    "https://gaussian37.github.io/dl-concept-global_average_pooling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dQpZtopug4ns",
    "outputId": "7c42c3ab-7b7d-49a6-b8b2-b25c0ceac158"
   },
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# def test():\n",
    "#     net = VGG('VGG11')\n",
    "#     x = torch.randn(2,3,32,32)\n",
    "#     y = net(x)\n",
    "#     print(y.size())\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-4           [-1, 64, 16, 16]               0\n",
      "            Conv2d-5          [-1, 128, 16, 16]          73,856\n",
      "       BatchNorm2d-6          [-1, 128, 16, 16]             256\n",
      "              ReLU-7          [-1, 128, 16, 16]               0\n",
      "         MaxPool2d-8            [-1, 128, 8, 8]               0\n",
      "            Conv2d-9            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-10            [-1, 256, 8, 8]             512\n",
      "             ReLU-11            [-1, 256, 8, 8]               0\n",
      "           Conv2d-12            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-13            [-1, 256, 8, 8]             512\n",
      "             ReLU-14            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-15            [-1, 256, 4, 4]               0\n",
      "           Conv2d-16            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-17            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-18            [-1, 512, 4, 4]               0\n",
      "           Conv2d-19            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-20            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-21            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-22            [-1, 512, 2, 2]               0\n",
      "           Conv2d-23            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-24            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-25            [-1, 512, 2, 2]               0\n",
      "           Conv2d-26            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-27            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-28            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-29            [-1, 512, 1, 1]               0\n",
      "        AvgPool2d-30            [-1, 512, 1, 1]               0\n",
      "           Linear-31                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 9,231,114\n",
      "Trainable params: 9,231,114\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.71\n",
      "Params size (MB): 35.21\n",
      "Estimated Total Size (MB): 38.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model     = VGG('VGG11').to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WD)\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "\n",
    "            test_loss += F.cross_entropy(output, target,\n",
    "                                         reduction='sum').item()\n",
    "\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.557156\n",
      "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 1.415737\n",
      "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 1.438557\n",
      "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 1.322118\n",
      "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 1.141386\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.099351\n",
      "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 1.111422\n",
      "Train Epoch: 1 [35840/50000 (71%)]\tLoss: 0.972152\n",
      "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 1.005072\n",
      "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 0.936210\n",
      "[1] Test Loss: 1.0175, Accuracy: 64.60%\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.830754\n",
      "Train Epoch: 2 [5120/50000 (10%)]\tLoss: 0.754580\n",
      "Train Epoch: 2 [10240/50000 (20%)]\tLoss: 0.751464\n",
      "Train Epoch: 2 [15360/50000 (31%)]\tLoss: 0.770648\n",
      "Train Epoch: 2 [20480/50000 (41%)]\tLoss: 0.732383\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.707951\n",
      "Train Epoch: 2 [30720/50000 (61%)]\tLoss: 0.766757\n",
      "Train Epoch: 2 [35840/50000 (71%)]\tLoss: 0.861021\n",
      "Train Epoch: 2 [40960/50000 (82%)]\tLoss: 0.739399\n",
      "Train Epoch: 2 [46080/50000 (92%)]\tLoss: 0.818614\n",
      "[2] Test Loss: 0.8372, Accuracy: 70.67%\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.588807\n",
      "Train Epoch: 3 [5120/50000 (10%)]\tLoss: 0.540938\n",
      "Train Epoch: 3 [10240/50000 (20%)]\tLoss: 0.537285\n",
      "Train Epoch: 3 [15360/50000 (31%)]\tLoss: 0.525718\n",
      "Train Epoch: 3 [20480/50000 (41%)]\tLoss: 0.489073\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.648476\n",
      "Train Epoch: 3 [30720/50000 (61%)]\tLoss: 0.547780\n",
      "Train Epoch: 3 [35840/50000 (71%)]\tLoss: 0.626890\n",
      "Train Epoch: 3 [40960/50000 (82%)]\tLoss: 0.602721\n",
      "Train Epoch: 3 [46080/50000 (92%)]\tLoss: 0.662790\n",
      "[3] Test Loss: 0.7614, Accuracy: 73.62%\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.342254\n",
      "Train Epoch: 4 [5120/50000 (10%)]\tLoss: 0.326802\n",
      "Train Epoch: 4 [10240/50000 (20%)]\tLoss: 0.397335\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, EPOCHS \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     train(model, train_loader, optimizer, epoch)\n\u001b[0;32m      3\u001b[0m     test_loss, test_accuracy \u001b[39m=\u001b[39m evaluate(model, test_loader)\n\u001b[0;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m] Test Loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m, Accuracy: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m      6\u001b[0m           epoch, test_loss, test_accuracy))\n",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m      6\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[0;32m      7\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(output, target)\n\u001b[1;32m----> 8\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m      9\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     11\u001b[0m \u001b[39mif\u001b[39;00m batch_idx \u001b[39m%\u001b[39m \u001b[39m20\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\NullA\\realanaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\NullA\\realanaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
    "          epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hmm..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4_3_CNN_VGG_ResNet_Cifar10_Practice.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d97a0948663b0b2eced954f294a163a1ac62d5a5cf016fffcde35ae285e7c733"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
